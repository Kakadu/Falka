{
//  UserLexer.fs contains simple lexer for testing.
//
//  for build:  fslex Lexer.fsl --unicode -o Lexer.fs
//
//  Copyright 2010, 2011, 2011 Semen Grigorev <rsdpisuy@gmail.com>
//
//  This file is part of YaccConctructor.
//
//  YaccConstructor is free software:you can redistribute it and/or modify
//  it under the terms of the GNU General Public License as published by
//  the Free Software Foundation, either version 3 of the License, or
//  (at your option) any later version.
//
//  This program is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
//  GNU General Public License for more details.
//
//  You should have received a copy of the GNU General Public License
//  along with this program.  If not, see <http://www.gnu.org/licenses/>.

module Test3.Lexer
open Microsoft.FSharp.Text.Lexing
open Microsoft.FSharp.Text
open Microsoft.FSharp.Reflection

type token = 
  | EOF of string
  | KW_CREATE of string
  | KW_FUNCTION of string
  | KW_RETURN   of string
  | KW_SELECT  of string
  | KW_FROM of string
  | KW_BEGIN of string
  | KW_END of string
  | STRING_CONST of string
  | DEC_NUMBER of string
  | IDENT of string
  | GLOBALVAR of string
  | GLOBALTEMPOBJ of string
  | LOCALVAR of string
  | TEMPOBJ of string
  | DOT of string
  | COMMA of string
  | OP_PLUS of string
  | OP_EQ of string
  | OP_MINUS of string
  | OP_DIV of string
  | LPAREN of string
  | RPAREN of string
  | LBRACKET of string
  | RBRACKET of string
  | SEMI of string

let getKwToken (name: string) = 
    let s = name.ToLower()
    match s with
    | "select"    -> KW_SELECT s
    | "from"      -> KW_FROM s
    | "create"    -> KW_CREATE s
    | "function"  -> KW_FUNCTION s
    | "return"    -> KW_RETURN s
    | "begin"     -> KW_BEGIN s
    | "end"       -> KW_END s
    | _           -> IDENT name

let comment_depth = ref 0
let startPos = ref Position.Empty
let str_buf = new System.Text.StringBuilder()

let appendBuf (str:string) = str_buf.Append(str) |> ignore
let clearBuf () = str_buf.Clear() |> ignore
  
let makeIdent notKeyWord (name:string) =
  let prefix = 
    if String.length name >=2 
    then name.[0..1] 
    else ""
  if prefix = "@@" then GLOBALVAR name
  else if prefix = "##" then GLOBALTEMPOBJ name
  else if name.[0] = '@' then LOCALVAR name
  else if name.[0] = '#' then TEMPOBJ name
  else if notKeyWord then IDENT name
  else getKwToken name
}

let anything = ['a'-'z' 'A'-'Z' '0'-'9' '\n' '\r' ' ' ] + 
let lparen = '('
let rparen = ')'
let eol = '\r' | '\n' | '\r' '\n' (* See script.sql position (4560,27) *)
let string_const = '\'' ['a'-'z' 'A'-'Z' '0'-'9' '-' '+' '*' '/' ' ' ]+ '\'' (* TODO: support line like 'aaa''aa' *)
let whitespaces = [' '  '\t']+
let ident_start_char  = ['A'-'Z' 'a'-'z' '_' '@' '#' 'а'-'я' 'А'-'Я' ] 
let ident_body_char  = ['A'-'Z' 'a'-'z' '_' '0'-'9' '@' '#' '$' 'а'-'я' 'А'-'Я' ] 
// Разобраться с идентификаторами cyrillic с,а (885574,_) (1004524)
let with_dot = '.' | ident_body_char
let ident = ident_start_char ident_body_char*
let decnumber = ['0'-'9']+ 
let hexnumber = "0x" ['0'-'9' 'a'-'f' 'A'-'F']+
let float_e = 'e' | 'E'
let floatnumber = decnumber ('.' decnumber)? ( float_e decnumber) ? (* what with 100.   ?? *)
let label = ident ':'


rule tokens = parse
 | eol          { tokens lexbuf }
 | string_const { STRING_CONST (LexBuffer<_>.LexemeString(lexbuf)) }
 | decnumber    { DEC_NUMBER   (LexBuffer<_>.LexemeString(lexbuf)) }
 | whitespaces  { tokens lexbuf }
 | "."          { DOT "." }
 | ","          { COMMA "," }
 | "="          { OP_EQ "=" }
 | ";"          { SEMI ";" }
 | "("          { LPAREN "(" }
 | ")"          { RPAREN ")" }
 | "["          { LBRACKET "(" }
 | "]"          { RBRACKET "]" }
 | "+"          { OP_PLUS "+" }
 | "-"          { OP_MINUS "-" }
 | ident {  let l = LexBuffer<_>.LexemeString(lexbuf) in
            makeIdent false l 
         }
 | "--" [^'\r' '\n']*  { tokens lexbuf }
 | "/*" { comment_depth := 1; clearBuf(); multiline_comment lexbuf }
 | eof  { EOF "" }
 | _    { failwith (sprintf "fucking shit received %s\n" (LexBuffer<_>.LexemeString(lexbuf)) ) }
and multiline_comment = parse
  | "/*" 
    { incr comment_depth; appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf}
  | "*/"
    { decr comment_depth; 
      if !comment_depth = 0 then 
        tokens lexbuf
      else 
        appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf 
    }
  | eol {lexbuf.EndPos <- lexbuf.EndPos.NextLine; appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf }
  | eof { failwith "unclosed comment in the end of file" }
  | [^ '\r' '\n' '*' '/']+ { appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf } 
  | _ { appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf } 

{}